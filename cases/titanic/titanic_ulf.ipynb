# -*- coding: utf-8 -*-
"""
Created on Thu Jun  2 10:04:06 2022

@author: bergmann
"""




#%%

def cria_modelo_random_forest(dados):
    from sklearn.model_selection import train_test_split
    
    x = dados.drop('Survived' , axis=1)
    y = dados['Survived']
    
    x_treino, x_teste, y_treino, y_teste = train_test_split(x , y)
        
    """# Random Forest"""
    from sklearn.ensemble import RandomForestClassifier
    from xgboost.sklearn import XGBClassifier
    from sklearn.model_selection import GridSearchCV
    
    #Creating search parameters for the GridSearchCV
    search_parameters = [{'n_estimators': [1000],'criterion': ['gini', 'entropy'],'max_depth': [10, 11, 12],'max_leaf_nodes': [18, 19, 20], 'min_samples_leaf': [1],'min_samples_split': [2]}]
    
    #Creating a random forest instance and using GridSearchCV to find the optimal parameters:
    rf_cls_CV = RandomForestClassifier(oob_score = True, random_state = 10)
    
    grid = GridSearchCV(estimator = rf_cls_CV, param_grid = search_parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)
    
    rf_grid = grid.fit(x_treino , y_treino)
    
    print('Best parameters for random forest classifier: ', rf_grid.best_params_, '\n')
    
    
    #Creating a random forest model based on the optimal paramters given by GridSearchCV:
    rf_grid_model = RandomForestClassifier(n_estimators = rf_grid.best_params_.get('n_estimators'),criterion = rf_grid.best_params_.get('criterion'),max_depth = rf_grid.best_params_.get('max_depth'),max_leaf_nodes = rf_grid.best_params_.get('max_leaf_nodes'),min_samples_leaf = rf_grid.best_params_.get('min_samples_leaf'),min_samples_split = rf_grid.best_params_.get('min_samples_split'),oob_score = True,random_state = 10, n_jobs = -1)
    
    rf_grid_model = rf_grid_model.fit(x_treino , y_treino)
    
    print('score RandomForestClassifier:' + str( rf_grid_model.score( x_teste , y_teste))) 

    return rf_grid_model
    
#%%    

def cria_modelo_TreeDecision(dados):
    SEED = 49
    from sklearn.model_selection import train_test_split

    x = dados.drop('Survived' , axis=1)
    y = dados['Survived']

    x_treino, x_teste, y_treino, y_teste = train_test_split(x , y)

    from sklearn import tree

    clf_tree = tree.DecisionTreeClassifier(random_state=SEED , max_depth=5)

    clf_tree.fit(x_treino , y_treino)

    print('score real:' + str( clf_tree.score( x_teste , y_teste)))

    from sklearn import dummy

    clf_dummy = dummy.DummyClassifier(random_state=SEED , strategy = 'most_frequent')

    clf_dummy.fit(x_treino , y_treino)

    print('score dummy:' + str(clf_dummy.score(x_teste , y_teste)))
    
    return clf_tree

def cria_modelo_SVC(dados):
    SEED = 49
    from sklearn.model_selection import train_test_split

    x = dados.drop('Survived' , axis=1)
    y = dados['Survived']

    x_treino, x_teste, y_treino, y_teste = train_test_split(x , y)
    
    
    
    from sklearn import svm
    clf = svm.SVC(random_state=SEED)
    
    clf.fit(x_treino , y_treino)

    print('score SVC:' + str( clf.score( x_teste , y_teste)))

    from sklearn import dummy

    clf_dummy = dummy.DummyClassifier(random_state=SEED , strategy = 'most_frequent')

    clf_dummy.fit(x_treino , y_treino)

    print('score dummy:' + str(clf_dummy.score(x_teste , y_teste)))
    
    return clf
#%%



#%%    
#Defining a function to extract the honorific from a name:
def extract_honorific(name):
    record = False
    honorific = ''
    for i, char in enumerate(name):
        if char == ',':
            record = True
        if char == '.':
            record = False
        if record == True:
            honorific += name[i + 2]
    return honorific[:-1]


def preparar_dados_1(dados):

    gerar_honorific_e_age_com_media(df)

    #remover features de identificacao
    df.drop(['PassengerId' , 'Name' , 'Ticket' , 'Cabin' ] , axis=1 , inplace = True)
    
    #preencher Embarked com a cidade que mais passageiros entraram
    df['Embarked'].fillna((df['Embarked'].mode()[0]), inplace = True)
    
    # Variaveis categoricas em string para inteiros 
    names = dados['Sex'].unique()
    values = list(range(1, names.size + 1))
    dados['Sex']= dados['Sex'].replace(names,values)
    
    names = dados['Embarked'].unique()
    values = list(range(1, names.size + 1))
    dados['Embarked']= dados['Embarked'].replace(names,values)

    names = dados['Honorific'].unique()
    values = list(range(1, names.size + 1))
    dados['Honorific']= dados['Honorific'].replace(names,values)
   
def gerar_honorific_e_age_com_media(dados):
    
    #Finding the honorifics of all the passengers:
    honorifics = [extract_honorific(name) for name in dados.Name]

    #Creating a new "Honorific" column:
    dados.insert(3 , "Honorific", honorifics)
    
    #COmpletar a idade com a média da idade de acordo com o honorifico que esta no meio do nome.

    median_ages = pd.Series(dados.groupby(by = 'Honorific')['Age'].median())
    median_ages.sort_values(ascending = False)
    
    for i, row in dados.iterrows():
        
        anAge = row['Age']
        anHonorific = row['Honorific']
        if  pd.isnull(anAge):
            if anHonorific in median_ages:  
                dados.at[i , 'Age'] = median_ages[anHonorific]
    
#%%

import pandas as pd
import numpy as np
from numpy import random

arquivo = 'C:/Users/bergmann/OneDrive/Python/titanic/dados/train.csv'
df_1  = pd.read_csv(arquivo)
tamanho_df_treino = df_1.shape[0]

arquivo = 'C:/Users/bergmann/OneDrive/Python/titanic/dados/test.csv'
df_2  = pd.read_csv(arquivo)
df_teste_pass_id = df_2['PassengerId']

#combinar arquivos de treino e teste
df = pd.concat( [df_1 , df_2] , axis=0 , ignore_index=True)

preparar_dados_1(df)

print(df.isnull().sum())
print(df.dtypes)

#%%

#separar arquivos de treino e teste
df_teste = df.iloc[tamanho_df_treino:] 
df_teste = df_teste.drop(['Survived'] , axis=1 , inplace=False)

df_treino = df.iloc[:tamanho_df_treino]

clf_rf = cria_modelo_random_forest(df_treino)
clf_svc = cria_modelo_SVC(df_treino)
clf_tree = cria_modelo_TreeDecision(df_treino)

#%%

#dados de teste tem um Fare que é nulo
df_teste['Fare'] = df_teste['Fare'].replace(np.nan, 10 )

result = clf_rf.predict(df_teste)

df_result = pd.DataFrame()
df_result['PassengerId'] = df_teste_pass_id 
df_result['Survived'] = result.astype(int)

df_result.to_csv( 'C:/Users/bergmann/OneDrive/Python/titanic/dados/ulf_ft.csv' , index=False)
#%%
